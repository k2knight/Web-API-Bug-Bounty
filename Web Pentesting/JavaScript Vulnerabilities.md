# JavaScript Vulnerabilities

### Method 1
Using Mantra

Collect all JS files using katana or manual 

```
katana -u <URL> -jc -d <Depth_number> -o url.txt
```

filter only JS files.
```
cat url.txt | grep ".js$" > js.txt
```

Find Vulns using [Mantra](https://github.com/MrEmpy/mantra) 

```
cat js.txt | mantra
```

Increase the Depth_number to find more urls.

### Method 2
Using SecretFinder

After having all JS file URLs

```
cat JS.txt | while read url; do python3 SecretFinder.py -i $url -o cli >> secrets.txt; done
```

### Method 3
Using burp extension (passive)

https://github.com/hisxo/JSpector
BurpJSLinkFinder (Burp Pro Extension)
XKeys (Burp Pro Extension)
### Method 4

Run the below code in the website console. It will list all the JS file URLs

```
var entries = performance.getEntriesByType('resource');
entries.map(function(entry) {
  if (entry.initiatorType === 'script') {
    console.log('JS file:', entry.name);
  }
});
```

### Method 5

Copy the below code and save it as a bookmark. when we are in a page click on that bookmark. It extract all endpoints (starting with /) from your current DOM and from all the all the external script sources embedded on the page.
https://0-a.nl/jsendpoints.txt

```
javascript:(function(){var scripts=document.getElementsByTagName("script"),regex=/(?<=(\"|\'|\`))\/[a-zA-Z0-9_?&=\/\-\#\.]*(?=(\"|\'|\`))/g;const results=new Set;for(var i=0;i<scripts.length;i++){var t=scripts[i].src;""!=t&&fetch(t).then(function(t){return t.text()}).then(function(t){var e=t.matchAll(regex);for(let r of e)results.add(r[0])}).catch(function(t){console.log("An error occurred: ",t)})}var pageContent=document.documentElement.outerHTML,matches=pageContent.matchAll(regex);for(const match of matches)results.add(match[0]);function writeResults(){results.forEach(function(t){document.write(t+"<br>")})}setTimeout(writeResults,3e3);})();
```


### Method 6

Parse the entire website and filter the JS files with filter by extension.

### Method 7

From a JS file it will grep all the endpoints 
```
cat main.js | grep -oh "\"\/[a-zA-Z0-9_/?=&]*\"" | sed -e 's/^"//' -e 's/"$//' | sort -u
```

### Method 8 (Effective)

parse the entire js file and finds the endpoints like `"Notifications/GenerationSignedURL"`

```
grep -Eo '"[A-Za-z]+/[A-Za-z0-9_/]+"' main.js
```

After the above command filter out all unnessary like application/data etc. (edit the 2nd grep command accordingly)
```
grep -Eo '"[A-Za-z]+/[A-Za-z0-9_/]+"' all.txt | grep -v -E 'application|text|image|video|audio|pdf|d/m|m/d|xl|MM|Yes|AM|A|Utility|AB|True|On|worksheets' > all_filtered.txt
```

Finds the URLs and endpoints
```
grep -Eo '(https?://[A-Za-z0-9./?=_-]+|/[A-Za-z0-9_/.-]+)' main.js
```

### Method 9

Node JS Script to find End points and URL's

`npm below_script.js main_javascript.js`

```
const fs = require('fs');

// Function to analyze each line and extract likely API endpoints
function extractApiEndpoints(filePath) {
    const apiEndpoints = new Set();
    const fileExtensions = ['.png', '.jpg', '.jpeg', '.gif', '.html', '.css', '.js', '.json', '.xml', '.pdf', '.svg']; // Add more extensions as needed
    const excludedPrefixes = ['application/', 'assets/', 'audio/', 'image/', 'multipart/', 'video/', 'text/', 'xl/']; // Add more prefixes as needed

    // Read file content
    const content = fs.readFileSync(filePath, 'utf-8');

    // Process each line
    content.split('\n').forEach(line => {
        // Find strings within quotes, which may contain endpoints
        const matches = line.match(/["'`](.*?)["'`]/g);

        if (matches) {
            matches.forEach(match => {
                // Remove the surrounding quotes and trim whitespace
                const potentialEndpoint = match.slice(1, -1).trim();

                // Filter for valid API endpoints, excluding HTML/XML patterns
                if (
                    potentialEndpoint.includes('/') &&           // Contains a slash (common in paths)
                    !potentialEndpoint.startsWith('http') &&    // Exclude full URLs
                    !potentialEndpoint.startsWith('<') &&       // Exclude HTML tags
                    !potentialEndpoint.includes(':') &&         // Exclude MIME types
                    !potentialEndpoint.includes('/pages/') &&   // Exclude paths with 'pages/'
                    !potentialEndpoint.includes('/>') &&        // Exclude closing tags like `/>`
                    !potentialEndpoint.includes('</') &&        // Exclude closing tags like `</tag>`
                    !potentialEndpoint.includes('>') &&         // Exclude tags containing `>`
                    potentialEndpoint.length < 100 &&           // Reasonable length for an endpoint
                    !fileExtensions.some(ext => potentialEndpoint.endsWith(ext)) && // Exclude common file types
                    !excludedPrefixes.some(prefix => potentialEndpoint.startsWith(prefix)) && // Exclude specific prefixes
                    !/\s/.test(potentialEndpoint)                // Exclude endpoints with spaces in between
                ) {
                    apiEndpoints.add(potentialEndpoint);
                }
            });
        }
    });

    // Convert the Set to a sorted array
    return Array.from(apiEndpoints).sort();
}

// Get the file path from command-line arguments
const filePath = process.argv[2];
if (!filePath) {
    console.error("Please provide a file path as a parameter.");
    process.exit(1);
}

// Execute the extraction and output sorted, unique results
try {
    const endpoints = extractApiEndpoints(filePath);
    console.log("Sorted, Unique API Endpoints:");
    endpoints.forEach(endpoint => console.log(endpoint));
} catch (error) {
    console.error("Error processing the file:", error.message);
}

```